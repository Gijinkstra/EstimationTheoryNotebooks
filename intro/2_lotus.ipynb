{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-09T14:05:32.740369Z",
     "start_time": "2025-07-09T14:05:32.204009Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy.integrate as integrate"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Expectations and LotUS\n",
    "\n",
    "The law of the unconscious statistician (LotUS) states that if $X$ is a real-valued continuous random variable with pdf $p_X$ and $h$ is a function such that ${\\rm I\\!E}[h(X)]$ exists, then\n",
    "$${\\rm I\\!E}[h(X)] = \\int_{-\\infty}^{+\\infty}h(x) p_X(x) \\mathrm{d}x.$$\n",
    "In the multivariate case, where $X$ is an ${\\rm I\\!R}^n$-valued random vector and $h:{\\rm I\\!R}^n\\to{\\rm I\\!R}^m$ LotUS becomes\n",
    "$${\\rm I\\!E}[h(X)] = \\int_{{\\rm I\\!R}^m}h(x) p_X(x) \\mathrm{d}x.$$\n",
    "These integrals can be computed analytically (quite rarely) or (typically) numerically."
   ],
   "id": "bda2c6fe37de31e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:07:49.495291Z",
     "start_time": "2025-07-09T14:07:49.478221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example 1: Suppose X ~ N(0, 1) and h(x) = cos(x)\n",
    "h = lambda x: np.cos(x)\n",
    "p_x = lambda x: stats.norm.pdf(x)\n",
    "integrand = lambda x: h(x) * p_x(x)\n",
    "e1 = integrate.quad(integrand, -np.inf, np.inf)\n",
    "print(f\"The expectation is ≈{e1[0]:.3f} (abs. err: {e1[1]:.2e})\")"
   ],
   "id": "67705dd8b9b723b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The expectation is ≈0.607 (abs. err: 9.21e-09)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.1. Exercises\n",
    "\n",
    "1. Suppose $X\\sim\\mathcal{N}(0, 1)$. Compute ${\\rm I\\!E}[X^2]$.\n",
    "2. Suppose $X\\sim\\mathcal{N}(0, 1)$. Compute ${\\rm I\\!E}[\\sin(X + 1)]$.\n",
    "3. Suppose $X\\sim\\mathrm{Beta}(4, 5)$. Compute ${\\rm I\\!E}[X1_{\\geq 0.2}(X)]$, where $1_{\\geq 0.2}$ is the function\n",
    "$$1_{\\geq 0.2}(x) = \\begin{cases}1, & \\text{ if } x \\geq 0.2, \\\\ 0, & \\text{ otherwise}\\end{cases}$$"
   ],
   "id": "a291284427279452"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.2. Multivariate case\n",
    "\n",
    "In the multivariate case we can use `scipy.integrate.nquad`. As an example, suppose $X\\sim\\mathcal{N}(0, \\Sigma)$, where $\\Sigma$ is a given symmetric positive definite covariance matrix, and we want to determine ${\\rm I\\!E}[\\|X\\|_2^2]$. Recall that $\\|X\\|_2^2 = X_1^2 + \\ldots + X_n^2$. We will give an example with $n = 3$ and you will then generalise it to arbitrary $n$.\n",
    "\n",
    "**Warning:** Integration in high dimensions is computationally challenging!\n"
   ],
   "id": "dceb82b07c52b9c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:35:29.795467Z",
     "start_time": "2025-07-09T14:35:28.371119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mu = [0, 0]\n",
    "# Let us construct a random symmetric positive definite matrix\n",
    "L = 0.1 * np.random.uniform(0, 1, (2, 2))\n",
    "Sigma = L @ L.T + np.eye(2)\n",
    "\n",
    "h = lambda *x: np.sum(np.array(x)**2) * stats.multivariate_normal.pdf(x, mu, Sigma)\n",
    "M = np.inf # large number (or infinity; may take longer)\n",
    "norm_squared_expectation = integrate.nquad(h, [[-M, M], [-M, M]])\n",
    "print(f\"Expectation of sq. norm: {norm_squared_expectation[0]:.3f} (abs. err: {norm_squared_expectation[1]:.2e})\")"
   ],
   "id": "2b60d5ad92934fd9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expectation of sq. norm: 0.962 (abs. err: 1.39e-08)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T14:52:23.448316Z",
     "start_time": "2025-07-09T14:42:40.814690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exercise: implement the following function and record how long it takes to run for n = 3\n",
    "#           (warning: it will take several minutes)\n",
    "def exp_nrm_sq(n):\n",
    "    \"\"\"\n",
    "    Computes\n",
    "    :param n: dimension\n",
    "    :return: expectation of ||X||^2\n",
    "    \"\"\"\n",
    "    mu = np.zeros(n, )\n",
    "    L = 0.1 * np.random.uniform(0, 1, (n, n))\n",
    "    Sigma = L @ L.T + np.eye(n)\n",
    "    h = 0 # Your code goes here\n",
    "    norm_exp = 0 # Your code goes here\n",
    "    return norm_exp\n",
    "\n",
    "print(exp_nrm_sq(3))"
   ],
   "id": "da157362fcf4d084",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.649513601905538\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2.3. Monte-Carlo integration*\n",
    "\n",
    "**Note:** We saw that numerical integration using `nquad` in three dimensions is already quite slow. It is much more efficient to use a Monte-Carlo integration method. We will not go into details, but if you are interested you can play with the following block of code"
   ],
   "id": "7182377c6421a730"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T15:03:14.150706Z",
     "start_time": "2025-07-09T15:03:13.907973Z"
    }
   },
   "cell_type": "code",
   "source": "import vegas",
   "id": "f7c59e068d443728",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-09T15:28:56.099392Z",
     "start_time": "2025-07-09T15:28:01.673670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def exp_nrm_sq_fast(n):\n",
    "    np.random.seed(0)\n",
    "    mu = np.zeros(n, )\n",
    "    L = 0.1*np.random.uniform(0, 1, (n, n))\n",
    "    Sigma = L @ L.T + np.eye(n)\n",
    "    h = lambda *x: (np.array(x)**2).sum() * stats.multivariate_normal.pdf(np.array(x), mu, Sigma)\n",
    "    M = 100\n",
    "    integ = vegas.Integrator([[-M, M]*n])\n",
    "    norm_exp = integ(h, nitn=10, neval=200_000, adapt=False)\n",
    "    # To increase precision we can increase either the number of iterations (nint)\n",
    "    # of the number of evaluations per iteration (neval); increasing the latter\n",
    "    # is more efficient.\n",
    "    return norm_exp\n",
    "\n",
    "result = exp_nrm_sq_fast(3)\n",
    "print(f\"Integral = {result.mean:.6f} +/- {result.sdev:.6f}\")\n"
   ],
   "id": "64cfe8440c980c64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral = 3.039205 +/- 0.001581\n"
     ]
    }
   ],
   "execution_count": 75
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
