{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T07:05:19.843692Z",
     "start_time": "2025-08-01T07:05:19.241718Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e37bde460e7b0d",
   "metadata": {},
   "source": [
    "## 1. Quick Mathematical Prelude\n",
    "\n",
    "Consider a function of the form $f:{\\rm I\\!R}^{m\\times n} \\to {\\rm I\\!R}$ (that maps matrices to scalars). An example of such a function is $f(A) = \\|Ax + b\\|_2^2$ (where $x$ and $b$ are constant). The derivative of $f$ with respect to $A$ is a function $\\frac{\\partial f(A)}{\\partial A}$ is a matrix-valued function such that\n",
    "$$\\left(\\frac{\\partial f(A)}{\\partial A}\\right)_{i,j} = \\frac{\\partial f(A)}{\\partial A_{i, j}}.$$\n",
    "In what follows we will use the formula\n",
    "$$\\frac{\\partial \\|Ax-b\\|_2^2}{\\partial A} = (Ax-b)x^\\intercal.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a272f9eba4a2cc5",
   "metadata": {},
   "source": [
    "## 2. Identification of linear systems\n",
    "\n",
    "Consider the dynamical system\n",
    "$$x_{t+1} = Ax_t + w_t,$$\n",
    "with the following assumptions:\n",
    "1. The noise, $w_t$, is iid, independent of the state, and has zero mean\n",
    "2. We can directly measure the state, $x_t$, and we have collected a set of measurements $x_0, \\ldots, x_N$\n",
    "3. The matrix $A$ is unknown and we need to estimate it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b79b3237175da",
   "metadata": {},
   "source": [
    "### 2.1. The least squares approach\n",
    "\n",
    "At every time $t=0,\\ldots, N-1$, the error is $w_t = Ax_t - x_{t+1}$. We can define the total error as\n",
    "$$e = \\sum_{t=0}^{N-1}\\|w_t\\|_2^2 = \\sum_{t=0}^{N-1}\\|Ax_t - x_{t+1}\\|_2^2.$$\n",
    "This is a function of $A$ and\n",
    "$$\\frac{\\partial e(A)}{\\partial A} = \\sum_{t=0}^{N-1} (Ax_t - x_{t+1})x_t^\\intercal = \\sum_{t=0}^{N-1} Ax_tx_t^\\intercal - \\sum_{t=0}^{N-1} x_{t+1}x_t^\\intercal.$$\n",
    "In order to determine the value of $A$ that minimises the error we will set the derivative to zero and solve for $A$; we have\n",
    "$$A \\cdot \\sum_{t=0}^{N-1} x_tx_t^\\intercal = \\sum_{t=0}^{N-1} x_{t+1}x_t^\\intercal.$$\n",
    "Provided $N > n$ chances are that $\\sum_{t=0}^{N-1} x_tx_t^\\intercal$ is full rank, thus invertible, so we can solve the above equation.\n",
    "\n",
    "### 2.2. Implementation\n",
    "Let $X = [x_0 ~ \\cdots ~ x_{N-1}]$ and $X^+ = [x_1 ~ \\cdots ~ x_N]$. Then, the above equation becomes\n",
    "$$A XX^\\intercal = X^{+}X^\\intercal \\Leftrightarrow XX^\\intercal A^\\intercal = XX^{+\\intercal}$$\n",
    "We can now solve this with [`np.linalg.solve`](https://numpy.org/doc/stable/reference/generated/numpy.linalg.solve.html) to determine $A^\\intercal$.\n",
    "\n",
    "### 2.3. Notation\n",
    "\n",
    "Hereafter, we will denote the unknown matrix by $A$ and the estimated matrix using $N$ samples by $\\hat{A}_N$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb2e49178162ec",
   "metadata": {},
   "source": [
    "## 4. Example\n",
    "\n",
    "Consider a system with\n",
    "$$A = \\begin{bmatrix}0.8 & 0.1 & 0.1 \\\\ -0.1 & 0.8 & -0.2 \\\\ 0 & 0 & 0.5\\end{bmatrix},$$\n",
    "and $w_t \\overset{\\text{iid}}{\\sim} \\mathcal{N}(0, Q)$ with $Q = 0.01 \\cdot I_3$. Let us generate $N$ states starting from $x_0=(1, 1, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8199985ebc5f61c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T07:06:11.794439Z",
     "start_time": "2025-08-01T07:06:11.786687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0717698481385967\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "A = np.array([[0.8, -0.1, 0.1],\n",
    "              [-0.1, 0.8, -0.2],\n",
    "              [0, 0, 0.5]])\n",
    "nx = A.shape[0]\n",
    "n_samples = 500\n",
    "Q = 0.01 * np.eye(nx)\n",
    "X = np.zeros((nx, n_samples+1))\n",
    "X[:, 0] = np.array([1, 1, 1])\n",
    "for t in range(n_samples):\n",
    "    wt = np.random.multivariate_normal(np.zeros(nx), Q)\n",
    "    X[:, t+1] = A @ X[:, t] + wt\n",
    "\n",
    "XXt = X[:, :n_samples-1] @ X[:, :n_samples-1].T\n",
    "XplusXt = X[:, :n_samples-1] @ X[:, 1:n_samples].T\n",
    "\n",
    "A_LS_estimate = np.linalg.solve(XXt, XplusXt).T\n",
    "print(np.linalg.norm(A_LS_estimate - A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216def29e0872d93",
   "metadata": {},
   "source": [
    "**Exercise:** Let us define the *average estimation error* (AEE) with $N$ samples as\n",
    "$$\\widehat{e}_N = \\tfrac{1}{N}\\sum_{t=0}^{N-1}\\|x_{t+1} - \\hat{A}_N x_t\\|_2^2,$$\n",
    "where $\\hat{A}_N$ is the estimated matrix $A$ using the above least-squares method.\n",
    "\n",
    "Plot AEE against the number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0caa850dc111994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69ec09b9978410",
   "metadata": {},
   "source": [
    "## 5. Exercise\n",
    "\n",
    "Consider the system\n",
    "$$x_{t+1} = \\underbrace{\\begin{bmatrix}0.8 & 0.1 & 0.1 & 0.3\\\\ -0.1 & 0.8 & -0.2 & 0\\\\ 0 & 0 & 0.5 & -0.5 \\\\ 0.1 & 0.2 & -0.1 & 0.05\\end{bmatrix}}_{A}x_t + \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix}u_t + w_t,$$\n",
    "where $w_t \\overset{\\text{iid}}{\\sim} \\mathcal{N}(0, Q)$ with $Q = 0.01 \\cdot I_4$ and $u_t$ are *known* inputs. Suppose that matrix $A$ is unknown and estimate it using observations $x_0, \\ldots, x_N$ and inputs $u_0, \\ldots, u_{N-1}$. Choose a sequence of inputs $u_0, \\ldots, u_{N-1}$ and estimate $A$ using the least squares method. You can choose the inputs to be iid samples of a random variable, e.g., $u_t\\overset{\\text{iid}}{\\sim}\\mathcal{N}(0, 1)$. Experiment with different values of $N$ and plot $\\widehat{e}_N$ against $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc8f01461f3e5bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T07:05:19.919800Z",
     "start_time": "2025-08-01T07:05:19.918343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05628891+0.j        ,  0.53830899+0.j        ,\n",
       "        0.83398996+0.07590625j,  0.83398996-0.07590625j])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code goes here\n",
    "A = np.array([[0.8, 0.1, 0.1, 0.3],\n",
    "              [-0.1, 0.8, -0.2, 0],\n",
    "              [0, 0, 0.5, -0.5],\n",
    "              [0.1, 0.2, -0.1, 0.05]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad9c6c",
   "metadata": {},
   "source": [
    "## 6. Constrained estimation\n",
    "\n",
    "More often than not we don't want to estimate the entire matrix $A$. We may know for example that certain elements of $A$ are zero, or are equal to a certain value. For example, we may know that the system dynamics is \n",
    "$$x_{t+1} = \\begin{bmatrix}\\textcolor{red}{0} & \\textcolor{red}{1} \\\\ \\textcolor{blue}{a_{2, 1}} & \\textcolor{red}{-1}\\end{bmatrix}x_t + w_t,$$\n",
    "where the only unknown is $a_{2, 1}$ (the elements in red are **known** and fixed; we only need to determine $a_{2,1}$).\n",
    "\n",
    "Suppose that we know that for certain indices $(i, j)\\in \\mathcal{I}$, the elements of $A$ are know and equal to some $\\bar{a}_{i, j}$, i.e., $A_{i, j} = \\bar{a}_{i, j}$ for $(i, j)\\in \\mathcal{I}$. In the above example, it is \n",
    "$$\\mathcal{I}=\\{(1, 1), (1, 2), (2,2)\\},$$\n",
    "i.e., the elements at $(1, 1)$, $(1, 2)$, and $(2, 2)$ are known and are equal to $\\bar{a}_{1, 1} = 0$, $\\bar{a}_{1, 2} = 1$, and $\\bar{a}_{2, 2} = -1$.\n",
    "\n",
    "In such cases we need to solve the following **constrained** optimisation problem\n",
    "$$\\begin{align}\n",
    "\\operatorname*{Minimise}_{A\\in{\\rm I\\!R}^{n\\times n}} \n",
    "&\\sum_{t=0}^{N-1}\\|Ax_t - x_{t+1}\\|_2^2\n",
    "\\\\\n",
    "\\text{subject to }& A_{i, j} = \\bar{a}_{i, j}, \\text{ for } (i, j) \\in \\mathcal{I}.\n",
    "\\end{align}$$\n",
    "\n",
    "This can be solved using the [KKT theorem](https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions). Next we will describe the methodology for determining $A$. You can find the proof in the lecture notes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8409e33b",
   "metadata": {},
   "source": [
    "### 6.1. Solution of constrained estimation problem\n",
    "\n",
    "**Step 1 (Matrix $\\Gamma$):** We construct the matrix $\\Gamma \\in {\\rm I\\!R}^{n^2\\times |\\mathcal{I}|}$, where $|\\mathcal{I}|$ is the number of elements of $\\mathcal{I}$, such that \n",
    "$$\\Gamma_{\\iota, s} = \n",
    "\\begin{cases}1, & \\text{ if } \\iota = (j-1)n + i \\\\\n",
    "0, &\\text{ otherwise}\\end{cases}$$\n",
    "\n",
    "**Step 2 (Vector $\\bar{a}$):** Collect the $\\bar{a}_{i, j}$ in a vector $\\bar{a} \\in {\\rm I\\!R}^{|\\mathcal{I}|}$ in [column-major order](https://en.wikipedia.org/wiki/Row-_and_column-major_order). \n",
    "\n",
    "**Step 3 (Computatioj of $B$ and $c$):** We define $\\tilde{x}_t = x \\otimes I_n$, where $\\otimes$ stands for the [Kronecker product](https://en.wikipedia.org/wiki/Kronecker_product), and $I_n$ is the $n\\times n$ identity matrix. We then define \n",
    "$$\\begin{align*}\n",
    "B ={}& \\sum_{t=0}^{N-1}\\tilde{x}_t \\tilde{x}_t^\\intercal,\n",
    "\\\\\n",
    "c={}& \\sum_{t=0}^{N-1}\\tilde{x}_t x_{t+1}.\n",
    "\\end{align*}$$\n",
    "Note that $B\\in{\\rm I\\!R}^{n^2\\times n^2}$ and $c\\in {\\rm I\\!R}^{n^2}$.\n",
    "\n",
    "**Step 4 (Solution):** Define $\\lambda = (G^\\intercal B^{-1} G)^{-1}(G^\\intercal B^{-1}c - \\bar{a})$ and \n",
    "$$a = B^{-1}(c - \\Gamma \\lambda).$$\n",
    "The vector $a\\in{\\rm I\\!R}^{n^2}$ contains the elements of $A$ in [column-major order](https://en.wikipedia.org/wiki/Row-_and_column-major_order).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89991c32",
   "metadata": {},
   "source": [
    "### 6.2. Example\n",
    "\n",
    "Consider the system \n",
    "$$x_{t+1} = \\begin{bmatrix}\n",
    "\\textcolor{red}{-0.9} & \\textcolor{blue}{a_{1,2}} &\\textcolor{red}{0.1}\\\\\n",
    "\\textcolor{red}{0}   &\\textcolor{red}{1}    &\\textcolor{blue}{a_{2, 3}}\\\\\n",
    "\\textcolor{red}{0}   &\\textcolor{blue}{a_{3, 2}}    &\\textcolor{red}{0.95}\\end{bmatrix}x_t + w_t,$$\n",
    "where the red entries are fixed. \n",
    "We have recorded a sequence of states in the file `example_6.2.csv`.\n",
    "We have \n",
    "$$\\mathcal{I} = \\{(1, 1), (2, 1), (3, 1), (2, 2), (1, 3), (3, 3)\\},$$\n",
    "where we have arranged the pairs of indices in [column-major order](https://en.wikipedia.org/wiki/Row-_and_column-major_order). The corresponding known entries are \n",
    "$$\\bar{a}=(-0.9, 0, 0, 1,  0.1, 0.95).$$\n",
    "Now in Python..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34c5c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices\n",
    "idx = [(1, 1), (2, 1), (3, 1), (2, 2), (1, 3), (3, 3)]\n",
    "a_bar = np.array([-0.9, 0, 0, 1,  0.1, 0.95]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ed40eb",
   "metadata": {},
   "source": [
    "Let us now create $\\Gamma$ in Python..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "94710a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "nI = len(idx)\n",
    "nx = 3\n",
    "\n",
    "Gam = np.zeros((nx**2, nI))\n",
    "for s in range(nI):\n",
    "    i_s = idx[s][0]\n",
    "    j_s = idx[s][1]\n",
    "    iot_s = (j_s-1)*nx + i_s -1 \n",
    "    Gam[iot_s, s] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0fa3a",
   "metadata": {},
   "source": [
    "Now let us compute $B$ and $c$ in Python. We will use the data in `example_6.2.csv`. To read the csv file, we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a75d8024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file\n",
    "states = np.genfromtxt('example_6.2.csv', delimiter=',')\n",
    "n_samples = states.shape[0]\n",
    "\n",
    "# Compute B and c\n",
    "B = 0; c = 0\n",
    "for t in range(n_samples-1):\n",
    "    x = states[t, :].reshape(-1, 1)\n",
    "    x_plus = states[t+1, :].reshape(-1, 1)\n",
    "    x_tilde = np.kron(x, np.eye(nx))\n",
    "    B = B + x_tilde @ x_tilde.T\n",
    "    c = c + x_tilde @ x_plus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99535c8",
   "metadata": {},
   "source": [
    "and now let us determine $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "64814c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.linalg.solve(B, c) # this is B^{-1}*c\n",
    "t2 = Gam.T @ t1 - a_bar\n",
    "t3 = np.linalg.solve(B, Gam)\n",
    "lam = np.linalg.solve(Gam.T@t3, t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d880b4",
   "metadata": {},
   "source": [
    "we can now estimate $A$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f1d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.00000000e-01,  1.63465216e-15,  5.17639849e-15],\n",
       "       [ 5.01189754e-01,  1.00000000e+00, -2.98810240e-01],\n",
       "       [ 1.00000000e-01,  1.39950987e-01,  9.50000000e-01]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_est = np.linalg.solve(B, c - Gam @ lam)\n",
    "a_est.reshape(nx, nx) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
